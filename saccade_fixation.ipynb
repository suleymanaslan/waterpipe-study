{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saccade_detection(data, min_len=5, max_vel=40, max_acc=340):\n",
    "\ts_sac = []\n",
    "\te_sac = []\n",
    "\n",
    "\tx = data[\"x\"]\n",
    "\ty = data[\"y\"]\n",
    "\ttime = data[\"VideoTime\"]\n",
    "\n",
    "\tint_dist = (np.diff(x)**2 + np.diff(y)**2)**0.5\n",
    "\tint_time = np.diff(time)\n",
    "\n",
    "\tvel = int_dist / int_time\n",
    "\tacc = np.diff(vel)\n",
    "\n",
    "\tt0i = 0\n",
    "\tstop = False\n",
    "\twhile not stop:\n",
    "\t\tsac_starts = np.where(np.logical_or(vel[t0i+1:] > max_vel, acc[t0i:] > max_acc))[0]\n",
    "\t\tif len(sac_starts) > 0:\n",
    "\t\t\tt1i = t0i + sac_starts[0] + 1\n",
    "\t\t\tif t1i >= len(time)-1:\n",
    "\t\t\t\tt1i = len(time)-2\n",
    "\t\t\tt1 = time[t1i]\n",
    "\n",
    "\t\t\ts_sac.append([t1])\n",
    "\n",
    "\t\t\tsac_ends = np.where(np.logical_and(vel[t1i+1:] < max_vel, acc[t1i:] < max_acc))[0]\n",
    "\t\t\tif len(sac_ends) > 0:\n",
    "\t\t\t\tt2i = sac_ends[0] + 1 + t1i + 2\n",
    "\t\t\t\tif t2i >= len(time):\n",
    "\t\t\t\t\tt2i = len(time)-1\n",
    "\t\t\t\tt2 = time[t2i]\n",
    "\t\t\t\tdur = t2 - t1\n",
    "\n",
    "\t\t\t\tif dur >= min_len:\n",
    "\t\t\t\t\te_sac.append([t1, t2, dur, x[t1i], y[t1i], x[t2i], y[t2i]])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ts_sac.pop(-1)\n",
    "\n",
    "\t\t\t\tt0i = 0 + t2i\n",
    "\t\t\telse:\n",
    "\t\t\t\tstop = True\n",
    "\t\telse:\n",
    "\t\t\tstop = True\n",
    "\n",
    "\treturn s_sac, e_sac\n",
    "\n",
    "def fixation_detection(data, max_dist=25, min_dur=50):\n",
    "\ts_fix = []\n",
    "\te_fix = []\n",
    "\n",
    "\tx = data[\"x\"].to_numpy()\n",
    "\ty = data[\"y\"].to_numpy()\n",
    "\ttime = data[\"VideoTime\"].to_numpy()\n",
    "\n",
    "\tsi = 0\n",
    "\tfix_start = False\n",
    "\tfor i in range(1,len(x)):\n",
    "\t\tsquared_distance = ((x[si]-x[i])**2 + (y[si]-y[i])**2)\n",
    "\t\tdist = 0.0\n",
    "\t\tif squared_distance > 0:\n",
    "\t\t\tdist = squared_distance**0.5\n",
    "\t\tif dist <= max_dist and not fix_start:\n",
    "\t\t\tsi = 0 + i\n",
    "\t\t\tfix_start = True\n",
    "\t\t\ts_fix.append([time[i]])\n",
    "\t\telif dist > max_dist and fix_start:\n",
    "\t\t\tfix_start = False\n",
    "\t\t\tif time[i-1]-s_fix[-1][0] >= min_dur:\n",
    "\t\t\t\te_fix.append([s_fix[-1][0], time[i-1], time[i-1]-s_fix[-1][0], x[si], y[si]])\n",
    "\t\t\telse:\n",
    "\t\t\t\ts_fix.pop(-1)\n",
    "\t\t\tsi = 0 + i\n",
    "\t\telif not fix_start:\n",
    "\t\t\tsi += 1\n",
    "\tif len(s_fix) > len(e_fix):\n",
    "\t\te_fix.append([s_fix[-1][0], time[len(x)-1], time[len(x)-1]-s_fix[-1][0], x[si], y[si]])\n",
    "\treturn s_fix, e_fix\n",
    "\n",
    "def add_saccades(data, e_sac):\n",
    "\tnb_steps = len(data[\"VideoTime\"])\n",
    "\tvts = data[\"VideoTime\"].to_numpy()\n",
    "\n",
    "\tvts = vts.reshape(nb_steps, 1)\n",
    "\n",
    "\tstart_times = np.tile(np.array(e_sac)[:,0], (nb_steps, 1))\n",
    "\tend_times = np.tile(np.array(e_sac)[:,1], (nb_steps, 1))\n",
    "\n",
    "\tdata['saccade'] = np.any(np.logical_and(vts >= start_times, vts <= end_times), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tracking_data = pd.read_csv('data/tracking/VR01_MENU_B.csv')\n",
    "# tracking_data['x'] = np.cos(tracking_data['gaze coord phi'])*np.sin(tracking_data[\" gaze coord theta\"])\n",
    "# tracking_data['y'] = np.sin(tracking_data['gaze coord phi'])*np.sin(tracking_data[\" gaze coord theta\"])\n",
    "#\n",
    "# s_sac, e_sac = saccade_detection(tracking_data, min_len=0, max_vel=0.4, max_acc=3.4)\n",
    "# add_saccades(tracking_data, e_sac)\n",
    "#\n",
    "# saccades_removed = tracking_data[tracking_data[\"saccade\"] == False]\n",
    "# saccades_removed = saccades_removed[saccades_removed[\"VideoTime\"] > 95]\n",
    "# saccades_removed = saccades_removed[saccades_removed[\"VideoTime\"] < 215]\n",
    "# plt.scatter(saccades_removed['x'], saccades_removed['y'], alpha=0.1)\n",
    "# plt.xlim(-1, 1)\n",
    "# plt.ylim(-1, 1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from IPython import display\n",
    "\n",
    "overlay_width = 7680//6\n",
    "overlay_height = 3840//6\n",
    "\n",
    "canvas_x_1 = (overlay_width*1.35)//3\n",
    "canvas_x_2 = (overlay_width*1.75)//3\n",
    "\n",
    "canvas_y_1 = (overlay_height*1.2)//4\n",
    "canvas_y_2 = (overlay_height*2.4)//4\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.imshow(np.flip(overlay_img, axis=0), origin='lower')\n",
    "# plt.xlim(canvas_x_1, canvas_x_2)\n",
    "# plt.ylim(canvas_y_1, canvas_y_2)\n",
    "# plt.savefig(\"overlay.png\", bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "demographics = pd.read_csv(f'data/demographics.csv')\n",
    "for p_id in demographics[\"Participant ID\"]:\n",
    "\tp_gender = demographics[demographics[\"Participant ID\"] == p_id][\"Gender\"].item()\n",
    "\tp_group = demographics[demographics[\"Participant ID\"] == p_id][\"Group\"].item()\n",
    "\tp_menu = \"A\" if p_group == 1 else \"B\"\n",
    "\tplot_color = \"r\" if p_gender == 1 else \"g\"\n",
    "\n",
    "\toverlay_img = imageio.imread(f\"data/screenshot_{p_menu}.PNG\")\n",
    "\toverlay_img = cv2.resize(overlay_img, (overlay_width, overlay_height))\n",
    "\n",
    "\ttracking_data = pd.read_csv(f'data/tracking/{p_id}_MENU_{p_menu}.csv')\n",
    "\ttracking_data['x'] = tracking_data['gaze coord phi']/np.pi\n",
    "\ttracking_data['y'] = tracking_data[\" gaze coord theta\"]/(np.pi/2)\n",
    "\ttracking_data['x'] = (tracking_data['x']+1)*0.5*overlay_width\n",
    "\ttracking_data['y'] = (tracking_data['y']+1)*0.5*overlay_height\n",
    "\ttracking_data = tracking_data[tracking_data[\"VideoTime\"] > 95]\n",
    "\ttracking_data = tracking_data[tracking_data[\"VideoTime\"] < 215]\n",
    "\n",
    "\t# plt.figure(figsize=(8, 8))\n",
    "\t# plt.imshow(np.flip(overlay_img, axis=0), origin='lower')\n",
    "\t# plt.scatter(tracking_data['x'], tracking_data['y'], alpha=0.1)\n",
    "\t# plt.xlim(canvas_x_1, canvas_x_2)\n",
    "\t# plt.ylim(canvas_y_1, canvas_y_2)\n",
    "\t# plt.savefig(\"overlay_tracking.png\", bbox_inches='tight')\n",
    "\t# plt.show()\n",
    "\n",
    "\ts_fix, e_fix = fixation_detection(tracking_data, max_dist=15, min_dur=0.05)\n",
    "\n",
    "\ttracking_fixations = pd.DataFrame({\"VideoTime\": np.array(e_fix)[:,0], \"x\": np.array(e_fix)[:,3], \"y\": np.array(e_fix)[:,4]})\n",
    "\ttracking_fixations = tracking_fixations[tracking_fixations[\"VideoTime\"] > 95]\n",
    "\ttracking_fixations = tracking_fixations[tracking_fixations[\"VideoTime\"] < 215]\n",
    "\n",
    "\t# plt.figure(figsize=(8, 8))\n",
    "\t# plt.imshow(np.flip(overlay_img, axis=0), origin='lower')\n",
    "\t# plt.scatter(tracking_fixations['x'], tracking_fixations['y'], color=\"b\", alpha=0.5)\n",
    "\t# plt.xlim(canvas_x_1, canvas_x_2)\n",
    "\t# plt.ylim(canvas_y_1, canvas_y_2)\n",
    "\t# plt.savefig(\"overlay_fixations.png\", bbox_inches='tight')\n",
    "\t# plt.show()\n",
    "\n",
    "\tplt.figure(figsize=(8, 8))\n",
    "\tplt.imshow(np.flip(overlay_img, axis=0), origin='lower')\n",
    "\ti = 0\n",
    "\tcur_x = tracking_fixations.iloc[i][\"x\"]\n",
    "\tcur_y = tracking_fixations.iloc[i][\"y\"]\n",
    "\tfor i in range(1, len(tracking_fixations)):\n",
    "\t\tnext_x = tracking_fixations.iloc[i][\"x\"]\n",
    "\t\tnext_y = tracking_fixations.iloc[i][\"y\"]\n",
    "\t\tplt.plot([cur_x, next_x], [cur_y, next_y], marker = 'o', c=plot_color, alpha=0.5)\n",
    "\t\tcur_x = next_x\n",
    "\t\tcur_y = next_y\n",
    "\tplt.xlim(canvas_x_1, canvas_x_2)\n",
    "\tplt.ylim(canvas_y_1, canvas_y_2)\n",
    "\tplt.savefig(f\"gif/trajectory/{'M' if p_gender == 1 else 'F'}_{p_id}.png\", bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\t# plt.show()\n",
    "\n",
    "\t# if not os.path.exists(f\"gif/{p_id}/\"):\n",
    "\t# \tos.mkdir(f\"gif/{p_id}/\")\n",
    "\t# anim_iter = 0\n",
    "\t# plt.figure(figsize=(8, 8))\n",
    "\t# plt.imshow(np.flip(overlay_img, axis=0), origin='lower')\n",
    "\t# plt.xlim(canvas_x_1, canvas_x_2)\n",
    "\t# plt.ylim(canvas_y_1, canvas_y_2)\n",
    "\t# i = 0\n",
    "\t# cur_x = tracking_fixations.iloc[i][\"x\"]\n",
    "\t# cur_y = tracking_fixations.iloc[i][\"y\"]\n",
    "\t# for i in range(1, len(tracking_fixations)):\n",
    "\t# \tnext_x = tracking_fixations.iloc[i][\"x\"]\n",
    "\t# \tnext_y = tracking_fixations.iloc[i][\"y\"]\n",
    "\t# \tplt.plot([cur_x, next_x], [cur_y, next_y], marker = 'o', c=plot_color, alpha=0.5)\n",
    "\t# \tcur_x = next_x\n",
    "\t# \tcur_y = next_y\n",
    "\t# \tplt.savefig(f\"gif/{p_id}/{anim_iter:04d}.png\", bbox_inches='tight')\n",
    "\t# \tanim_iter += 1\n",
    "\t# plt.close()\n",
    "\t# plt.show()\n",
    "\n",
    "\t# anim_file = f'gif/{p_id}.gif'\n",
    "\t#\n",
    "\t# frames = []\n",
    "\t# filenames = glob.glob(f'gif/{p_id}/*.png')\n",
    "\t# filenames = sorted(filenames)\n",
    "\t# for i, filename in enumerate(filenames):\n",
    "\t# \tframes.append(imageio.imread(filename))\n",
    "\t# for i in range(10):\n",
    "\t# \tframes.append(imageio.imread(filename))\n",
    "\t#\n",
    "\t# imageio.mimsave(anim_file, frames, 'GIF', fps=8)\n",
    "\t# display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
